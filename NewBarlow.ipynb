{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "103fc83f-a4f7-4d29-9a09-b6ab1772c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CONFIG_MAPPING, BertForMaskedLM, BertModel, BertPreTrainedModel, BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pdb\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25c4aaf-4d6c-4ce2-bc90-e0e3ca4d71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACT2FN = {\n",
    "    \"relu\": F.relu,\n",
    "    \"silu\": F.silu,\n",
    "    \"swish\": F.silu,\n",
    "    \"gelu\": F.gelu,\n",
    "    \"tanh\": torch.tanh,\n",
    "    \"sigmoid\": torch.sigmoid,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c2830f-c5b9-4baf-8ba2-78909499fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tiny = {\n",
    "    \"hidden_size\" : 128 ,\n",
    "    \"num_hidden_layers\" : 2,\n",
    "    \"num_attention_heads\": int(128/64),\n",
    "    \"intermediate_size\" : int(128*4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c277d19d-55c7-49c7-820c-9566e9235f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 128,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 512,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 2,\n",
       "  \"num_hidden_layers\": 2,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"projector\": \"128-128\",\n",
       "  \"transformers_version\": \"4.2.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = CONFIG_MAPPING['bert']()\n",
    "config.update(bert_tiny)\n",
    "config.projector='128-128'\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a4efc5e-200a-4f44-86f3-dc5c84926ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projector(nn.Module):\n",
    "    def __init__(self, config,input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_size, output_size,bias=False)\n",
    "        if isinstance(config.hidden_act, str):\n",
    "            self.transform_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.transform_act_fn = config.hidden_act\n",
    "        self.LayerNorm = nn.LayerNorm(output_size, eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.transform_act_fn(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ebc783-2e4a-4c6d-b19c-142b26c1ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def off_diagonal(x):\n",
    "    # return a flattened view of the off-diagonal elements of a square matrix\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "569987d5-b617-4246-82ef-a1f4c83e476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForBarlowTwins(BertPreTrainedModel):\n",
    "\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\", r\"predictions.decoder.bias\"]\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"Initialize the weights\"\"\"\n",
    "#         pdb.set_trace()\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "            \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        if config.is_decoder:\n",
    "            logger.warning(\n",
    "                \"If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for \"\n",
    "                \"bi-directional self-attention.\"\n",
    "            )\n",
    "            \n",
    "        self.bert = BertModel(config, add_pooling_layer=True)\n",
    "        \n",
    "        sizes = [config.hidden_size] + list(map(int, config.projector.split('-')))\n",
    "        layers = []\n",
    "        for i in range(len(sizes) - 2):\n",
    "            layers.append(Projector(config,sizes[i], sizes[i + 1]))\n",
    "        layers.append(Projector(config,sizes[-2], sizes[-1]))\n",
    "        self.projector = nn.Sequential(*layers)\n",
    "        self.bn = nn.BatchNorm1d((128,128), affine=False)\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "#     def get_output_embeddings(self):\n",
    "#         return self.cls.decoder\n",
    "\n",
    "#     def set_output_embeddings(self, new_embeddings):\n",
    "#         self.cls.decoder = new_embeddings\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "#         pdb.set_trace()\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        \n",
    "        projection = self.projector(outputs.pooler_output)\n",
    "        \n",
    "        return projection#,self.bn(projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f589e8-f2f5-40d1-b2e4-35b3fc039d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForBarlowTwins(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc80fbb1-1b70-4705-900c-5f152c3ecd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')#, padding=True,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36fb5efa-8866-4ded-b0b6-6477febc4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"pt\",padding='max_length',truncation=True)\n",
    "input_2 = tokenizer(\"I am going to Berlin.\", return_tensors=\"pt\",padding='max_length',truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2256548-1bfe-42e4-9cfd-e7f85b3905aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73da9c922fba46b39d85fac4151ea24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1689.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28817131817e4d288478f057225d58a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=946.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset bookcorpus (/mounts/data/corp/huggingface/datasets/bookcorpus/plain_text/1.0.0/af844be26c089fb64810e9f2cd841954fd8bd596d6ddd26326e4c70e2b8c96fc)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('bookcorpus',split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "174f6050-5192-48f5-b43c-1db1ea8f69a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75b5bf2531b403fbaaf881dc3d7e336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_tokenized=dataset.select(range(100)).map(lambda e: tokenizer(e['text'],padding='max_length',truncation=True),remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0b1af82-a401-40ec-9997-3e9b199139fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tokenized.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b44cdee-22bd-43bb-bb1c-3f3b1083757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(min_tokenized,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cac65a4-6931-4e65-83b6-deae1d55f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8974f5a5-8089-4373-8931-5832ea5b2772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'input_ids': tensor([[ 101, 1996, 2431,  ...,    0,    0,    0],\n",
       "         [ 101, 3175, 1024,  ...,    0,    0,    0],\n",
       "         [ 101, 1045, 4299,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 1045, 2921,  ...,    0,    0,    0],\n",
       "         [ 101, 2788, 1045,  ...,    0,    0,    0],\n",
       "         [ 101, 1045, 6476,  ...,    0,    0,    0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e686c8-fd0d-480d-8e68-bd54ca00f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad(examples, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3701d049-d930-498d-a652-1352e87a831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1=model(**batch)\n",
    "z2=model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5fa126b6-9bdd-4029-9f0c-25401a459a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D = z1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8ae1bda-ffb2-454a-9151-7e19472a894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = torch.eye(D, device=z1.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa188ba-7dcd-4473-a3dc-a789b3a301f7",
   "metadata": {},
   "source": [
    "# Barlow Twins Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da9ff210-fc2b-4ad7-aa7d-578627dd12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1m = z1 - z1.mean(dim=0)\n",
    "z2m = z2 - z2.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8877c89f-804d-4d80-be3c-63089078671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=(z1m.T@z2m) / (N - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da1785f6-93ff-46a6-b3e5-5dfc28989a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9903, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diagonal(c).add_(-1).pow_(2).sum()/D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd5bef3b-6609-47d6-bf1c-9a493dcad05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0898, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_diagonal(c).pow_(2).sum()/D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "17011331-9cb8-43cc-8ca6-ea6739fe6330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0898, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[~diag.bool()].pow_(2).sum()/D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ced6e0-4d8d-43b2-a6dd-f8e8af6d0239",
   "metadata": {},
   "source": [
    "# Covariance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1eb9480a-204c-4b03-bce1-ec72747f06a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1m = z1 - z1.mean(dim=0)\n",
    "z2m = z2 - z2.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9702641-d33f-4256-b74a-282f87995ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3314, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_z1 = (z1m.T @ z1m) / (N - 1)\n",
    "cov_z2 = (z2m.T @ z2m) / (N - 1)\n",
    "\n",
    "cov_z1[~diag.bool()].pow_(2).sum() / D + cov_z2[~diag.bool()].pow_(2).sum() / D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfb81dc-ec3a-4e97-8bdd-70b4cd1daaa5",
   "metadata": {},
   "source": [
    "# Variance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "678bd330-2125-4f47-b157-92b68d1da349",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-4\n",
    "std_z1 = torch.sqrt(z1.var(dim=0) + eps)\n",
    "std_z2 = torch.sqrt(z2.var(dim=0) + eps)\n",
    "std_loss = torch.mean(F.relu(1 - std_z1)) + torch.mean(F.relu(1 - std_z2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c4b13d71-1dad-40d0-82e3-f3c6f2efd405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9bb8bb65-6cb3-45d6-a748-cbe8ec87babb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1805, 0.0803, 0.0371, 0.1373, 0.0327, 0.1542, 0.1113, 0.2210, 0.0287,\n",
       "        0.0155, 0.0603, 0.0897, 0.0307, 0.0185, 0.1443, 0.0727, 0.0291, 0.0170,\n",
       "        0.0093, 0.1019, 0.0976, 0.1299, 0.0944, 0.1271, 0.1457, 0.0797, 0.0220,\n",
       "        0.0729, 0.0923, 0.0574, 0.0942, 0.1191, 0.0574, 0.2731, 0.0997, 0.1672,\n",
       "        0.1743, 0.2080, 0.1008, 0.0405, 0.1845, 0.2886, 0.0398, 0.1831, 0.0500,\n",
       "        0.1044, 0.0511, 0.0836, 0.0214, 0.0311, 0.0970, 0.0383, 0.5869, 0.0233,\n",
       "        0.0834, 0.1279, 0.2007, 0.1390, 0.0073, 0.0905, 0.0634, 0.1566, 0.0673,\n",
       "        0.1147, 0.0595, 0.0555, 0.0945, 0.1078, 0.2833, 0.1474, 0.3221, 0.0831,\n",
       "        0.1491, 0.0134, 0.0560, 0.0723, 0.0554, 0.2790, 0.0747, 0.1271, 0.1810,\n",
       "        0.1856, 0.0646, 0.0758, 0.1822, 0.1752, 0.1077, 0.1482, 0.1098, 0.0858,\n",
       "        0.0497, 0.0699, 0.3350, 0.1854, 0.2708, 0.0408, 0.0538, 0.1051, 0.0951,\n",
       "        0.0192, 0.1096, 0.1308, 0.2213, 0.0155, 0.0703, 0.0480, 0.0424, 0.1252,\n",
       "        0.1210, 0.0377, 0.1597, 0.4602, 0.1113, 0.1406, 0.1209, 0.2521, 0.1261,\n",
       "        0.0410, 0.2130, 0.1373, 0.1406, 0.1090, 0.0126, 0.0309, 0.0547, 0.0295,\n",
       "        0.1917, 0.0502], grad_fn=<VarBackward1>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1.var(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a85f2233-4595-4bd7-a952-1159e57837ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8065, 0.8827, 0.8593, 0.7133, 0.8951, 0.6573, 0.7037, 0.7396, 0.6810,\n",
       "        0.8893, 0.7314, 0.5148, 0.8443, 0.8209, 0.6200, 0.8423, 0.8944, 0.8716,\n",
       "        0.9449, 0.6570, 0.7384, 0.7558, 0.7705, 0.7297, 0.6275, 0.8227, 0.8265,\n",
       "        0.8472, 0.6689, 0.7906, 0.7722, 0.7049, 0.7035, 0.7905, 0.7418, 0.6278,\n",
       "        0.6226, 0.7449, 0.5424, 0.7018, 0.6458, 0.6325, 0.8602, 0.8256, 0.8674,\n",
       "        0.6654, 0.7883, 0.8475, 0.8720, 0.7822, 0.7624, 0.8474, 0.6376, 0.9141,\n",
       "        0.8179, 0.7264, 0.7338, 0.8114, 0.9535, 0.7120, 0.7395, 0.8275, 0.6705,\n",
       "        0.8042, 0.9198, 0.8902, 0.7696, 0.7035, 0.6811, 0.7246, 0.5317, 0.6856,\n",
       "        0.8009, 0.9226, 0.9310, 0.7896, 0.7854, 0.6225, 0.7812, 0.6297, 0.7130,\n",
       "        0.6941, 0.7906, 0.8219, 0.3729, 0.5896, 0.7334, 0.6301, 0.7397, 0.8049,\n",
       "        0.7329, 0.8140, 0.5573, 0.7892, 0.6147, 0.7629, 0.8114, 0.7583, 0.7534,\n",
       "        0.8312, 0.7856, 0.7605, 0.7835, 0.8806, 0.7663, 0.6906, 0.9004, 0.7610,\n",
       "        0.7407, 0.7974, 0.6445, 0.5366, 0.6140, 0.6629, 0.5911, 0.4351, 0.7034,\n",
       "        0.8298, 0.6274, 0.6999, 0.5995, 0.7152, 0.9402, 0.7780, 0.7453, 0.7397,\n",
       "        0.6649, 0.8414], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.relu(1 - std_z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed8753c-1cc7-43d7-baf9-f1f690d27409",
   "metadata": {},
   "source": [
    "## BarlowBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25640339-446a-4500-bd3d-b1d3d724649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarlowBert(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = BertForBarlowTwins(config)\n",
    "        self.scale_loss = 1/32\n",
    "        self.lambd = 3.9e-3\n",
    "        \n",
    "    def forward(self, y1, y2):\n",
    "        output1 = self.model(**y1)\n",
    "        output2 = self.model(**y2)\n",
    "        \n",
    "        c = (output1.transpose(0,1) @ output2)\n",
    "        \n",
    "        # use --scale-loss to multiply the loss by a constant factor\n",
    "        # see the Issues section of the readme\n",
    "        on_diag = torch.diagonal(c).add_(-1).pow_(2).sum().mul(self.scale_loss)\n",
    "        off_diag = off_diagonal(c).pow_(2).sum().mul(self.scale_loss)\n",
    "        loss = on_diag + self.lambd * off_diag\n",
    "        return loss      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d448951-2aa9-4b9f-8478-a29056b6b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "barlow = BarlowBert(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3236d5d2-ed3e-42b5-a79d-89003b7bafbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24.7527, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barlow(input_1,input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf480f-f2d5-4c29-b99d-bb1bee1d49c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
