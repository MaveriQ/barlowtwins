{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a7f51b-b751-4036-b0d0-35d2ec748569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import datasets\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671ab7ac-9210-48f4-854e-747841468fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.CONFIG_MAPPING['bert']().from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa1c1034-35e8-4d0d-9ef8-e2d202443f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = transformers.BertModel(config, add_pooling_layer=False).from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34131735-b9af-479f-9b30-06a77797c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset bookcorpus (/mounts/data/corp/huggingface/datasets/bookcorpus/plain_text/1.0.0/44662c4a114441c35200992bea923b170e6f13f2f0beb7c14e43759cec498700)\n"
     ]
    }
   ],
   "source": [
    "corpus = datasets.load_dataset('bookcorpus',split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5178618-6810-4c7d-8955-c9e5c08859be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "618bdbbc-8151-4291-bc2b-de6641714e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mounts/data/corp/huggingface/datasets/bookcorpus/plain_text/1.0.0/44662c4a114441c35200992bea923b170e6f13f2f0beb7c14e43759cec498700/cache-2104a3e5d00ab1ee.arrow\n"
     ]
    }
   ],
   "source": [
    "mini_tokenized = corpus.select(range(16)).map(lambda e: tokenizer(e['text'],truncation=True,padding='max_length',max_length=128),remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c96885-d1ec-4a19-8e81-6ed664480d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_tokenized.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98ae769d-ffcd-490c-8913-905f4f065bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'token_type_ids'],\n",
       "    num_rows: 16\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a351444-8076-4916-8e07-0ea64d7ba667",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bert(input_ids = mini_tokenized['input_ids'],\n",
    "             attention_mask = mini_tokenized['attention_mask'],\n",
    "             output_hidden_states=True,\n",
    "#              output_attentions=True\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9c58324-8e32-4d8c-8151-ef5b85f563d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb579a93-8232-4e1b-9051-e85625d45893",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_attn = output.last_hidden_state * mini_tokenized['attention_mask'].unsqueeze(2).expand_as(output.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97c861d7-5368-4d51-82b5-62a1fc726602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b3183e4-80e8-4ec6-89dc-1c6cedbee549",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_p = torch.nn.Parameter(torch.rand(16,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7042abee-2310-4596-8111-54e5699e48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.rand(16,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dc0919e-a7fc-4964-872e-a20649da887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.bmm(weight_p.unsqueeze(1),output.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1168e1f-0028-4420-9135-b12a9287d58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose((weight_p.unsqueeze(2).expand_as(output.last_hidden_state)*output.last_hidden_state).sum(1),\n",
    "              out.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee3defc6-c7e3-4d28-8563-547d43b1340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterizedBertPooler(torch.nn.Module):\n",
    "    def __init__(self,bert_layers,seq_len,batch_size):#args,config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert_layers = bert_layers        \n",
    "        self.weight_parameter = [torch.nn.Parameter(torch.rand(batch_size,1,seq_len)) for j in range(self.bert_layers)]\n",
    "        \n",
    "    def forward(self,bert_output,attention_mask):\n",
    "        output = []\n",
    "        start = 12\n",
    "        end = 12-self.bert_layers\n",
    "        j=0\n",
    "        for i in range(start,end,-1): # go from 13 backwards\n",
    "            hidden_state = bert_output.hidden_states[i]\n",
    "            hidden_state_masked = hidden_state * attention_mask.unsqueeze(2).expand_as(hidden_state)\n",
    "            out = torch.bmm(self.weight_parameter[j],hidden_state_masked) # batched dot product\n",
    "            output.append(out.squeeze())\n",
    "            j+=1 # weight_parameter counter\n",
    "        \n",
    "        return torch.stack(output).transpose(0,1) # swap batch and layer_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7b1bfb1-20e3-4b23-a883-a57414ee9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralParameterizedPooler(torch.nn.Module):\n",
    "    def __init__(self,num_layers,seq_len,batch_size):#args,config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers        \n",
    "        self.weight_parameter = [torch.nn.Parameter(torch.rand(batch_size,1,seq_len)) for j in range(self.num_layers)]\n",
    "        \n",
    "    def forward(self,token_embeddings,attention_mask):\n",
    "        assert len(token_embeddings)==self.num_layers, 'Number of embeddings must be the same as number of layers'\n",
    "        output = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            hidden_state = token_embeddings[i]\n",
    "            hidden_state_masked = hidden_state * attention_mask.unsqueeze(2).expand_as(hidden_state)\n",
    "            out = torch.bmm(self.weight_parameter[i],hidden_state_masked) # batched dot product\n",
    "            output.append(out.squeeze())\n",
    "        \n",
    "        return torch.stack(output).transpose(0,1) # swap batch and layer_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a8cd1a-6250-4b80-82b8-57142bd864c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooler = ParameterizedBertPooler(3,128,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae45f3-1a2c-4658-a89e-bf2dd2d22c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooler.weight_parameter[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af513371-1773-42ac-9823-81bec001148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pooler.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae542716-8b7f-4772-a8a0-93ce25b3aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "poolerG = GeneralParameterizedPooler(3,128,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646d677-3e04-4463-9320-f0ffec13842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = poolerG(output.hidden_states[-3:],mini_tokenized['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81df554-50b0-4b0f-9cab-3d93d7ec280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ca46f-9d79-4e7d-aa3a-79841d35a031",
   "metadata": {},
   "source": [
    "## new parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024d3f4f-58e4-4469-b842-9d9aa1f62dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "seq_len = 128\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac88f290-05bb-4149-9ddb-37dc3168b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_param = [torch.nn.Parameter(torch.rand(seq_len)-0.5) for j in range(num_layers)]\n",
    "layer_param = torch.nn.Parameter(torch.rand(num_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e79d53-b6ab-43f1-bc19-7cb6460b789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_param[0].shape, layer_param.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374b8ae-c6e0-461c-9ca7-8c44457e6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78eacc-7057-44a2-8036-e9cc747a69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_param[0].expand([bs,1,seq_len]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7be4ce-cd7e-4095-ad37-f21a076ee6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a10b36-8b03-4a42-812f-094d1483d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=[torch.bmm(seq_param[i].expand([bs,1,seq_len]),output.hidden_states[i]).squeeze() for i in range(num_layers)]\n",
    "out = torch.stack(out).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f50ce5-52b7-4ce9-8116-37278adf102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96af11f-fb10-486e-bc2b-c93962528435",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.bmm(layer_param.expand(bs,1,num_layers),out).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "483cb938-e27d-4f51-922b-b69fc81f37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralParameterizedPooler(torch.nn.Module):\n",
    "    def __init__(self,num_layers,seq_len,hidden_dim,batch_size,already_masked=True):#args,config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.already_masked = already_masked\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.seq_weight_parameter = torch.nn.ParameterList([torch.nn.Parameter(torch.rand(seq_len)-0.5) for j in range(self.num_layers)]) # random numbers between [-0.5,0.5]\n",
    "        self.layer_weight_parameter = torch.nn.Parameter(torch.rand(num_layers)-0.5) # random numbers between [-0.5,0.5]\n",
    "        \n",
    "    def forward(self,token_embeddings,attention_mask):\n",
    "        assert len(token_embeddings)==self.num_layers, 'Number of embeddings must be the same as number of layers'\n",
    "        output = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            hidden_state = token_embeddings[i]\n",
    "            if self.already_masked:\n",
    "                hidden_state_masked = hidden_state\n",
    "            else:\n",
    "                hidden_state_masked = hidden_state * attention_mask.unsqueeze(2).expand_as(hidden_state)\n",
    "            weight_parameter = self.seq_weight_parameter[i].expand([self.batch_size,1,self.seq_len])\n",
    "            out = torch.bmm(weight_parameter,hidden_state_masked) # batched dot product\n",
    "            output.append(out.squeeze())\n",
    "            \n",
    "        layer_sentence_embeddings = torch.stack(output).transpose(0,1) # swap batch and layer_dimension\n",
    "        \n",
    "        model_sentence_embedding = torch.bmm(self.layer_weight_parameter.expand(self.batch_size,1,self.num_layers),layer_sentence_embeddings).squeeze()\n",
    "        \n",
    "        return {'sentence_embedding' : model_sentence_embedding}\n",
    "\n",
    "    def get_sentence_embedding_dimension(self):\n",
    "        return self.hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be3d554d-3963-46ef-afe5-7dcdc3caa594",
   "metadata": {},
   "outputs": [],
   "source": [
    "poolerG = GeneralParameterizedPooler(3,128,768,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df6b79-4fb4-4d5d-90d2-d7f7ea8286cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in poolerG.parameters():\n",
    "    print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee901d8c-4070-460b-ba64-c110a2c8520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = poolerG(output.hidden_states[-3:],mini_tokenized['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce945496-6215-496a-a9cd-dac6bb9554ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce947389-7814-4bbf-931e-24f452f822b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.rand(100)-0.5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae937358-5138-485f-af1d-de0929c6f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "poolerG.weight_parameter[1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6084ba-6c76-42d0-9676-8c003372d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv1d(in_channels=1,out_channels=512,kernel_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d257b6-ef6b-47ea-af57-12e488235efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d594235-2681-4344-acdf-9d04c687b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1(pooled.unsqueeze(1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ebc4a-dfbd-4043-a961-ef75d40d8d69",
   "metadata": {},
   "source": [
    "## CONV1D layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c5e7d5-a527-4f68-99e3-e0ff4af9ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = torch.cat(output.hidden_states[-3:],1)\n",
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fda417-09a2-4a8e-8a66-eaab95da0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv1d(in_channels=384,out_channels=512,kernel_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c6a38-8837-441b-a975-14c8c4303ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1(stacked).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b81b230a-aa2d-4027-8fba-484684fd038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1DLayers(torch.nn.Module):\n",
    "    def __init__(self,num_trainable_layers,seq_len,channels_list):#args,config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.out_channels = channels_list\n",
    "        self.num_trainable_layers = num_trainable_layers\n",
    "        \n",
    "        in_channels = num_trainable_layers * seq_len\n",
    "        out_channels = channels_list[0]\n",
    "        self.layer1 = torch.nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=1)\n",
    "        \n",
    "        in_channels = out_channels\n",
    "        out_channels = channels_list[1]\n",
    "        self.layer2 = torch.nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self,bert_output,attention_mask):\n",
    "        \n",
    "        attn_mask = attention_mask.unsqueeze(2).expand_as(bert_output[0])\n",
    "        selected_layers = bert_output.hidden_states[-self.num_trainable_layers:]\n",
    "        attended_bert_output = []\n",
    "        \n",
    "        for layer in selected_layers:\n",
    "            attended_bert_output.append(layer*attn_mask)\n",
    "            \n",
    "        stacked = torch.cat(attended_bert_output,dim=1)\n",
    "                \n",
    "        out_layer1 = self.layer1(stacked)\n",
    "        out_layer2 = self.layer2(torch.nn.ReLU()(out_layer1))\n",
    "        \n",
    "        return out_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49673325-0223-471e-a342-4e764e10b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = Conv1DLayers(3,128,[512,1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff1a3776-f258-4ccf-84d1-9b43f29ae711",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_out = conv(output,mini_tokenized['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "674595aa-b3c0-4ec1-9ec9-86d4d97c6794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1024, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6128abb0-6413-4ac1-91ba-72299d2e2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "poolerG = GeneralParameterizedPooler(1,1024,768,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91a51117-d41c-4f29-8b03-7fa287b4351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = poolerG([conv_out],mini_tokenized['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fc80e9c-f1ca-48aa-aff3-e5f27544387d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 768])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled['sentence_embedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e4defc-b89b-4aeb-b1d0-f21fad8097d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c654858d7ffcefc9ca7bcfbeaae13952adb60804da9d229cb7764625e8797c79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
